{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Terminología: AI, Machine Learning, Deep Learning, Big Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tipos de Proyectos:\n",
    "- CV (Computer Vision)\n",
    "- NLP (Natural Language Processing)\n",
    "- VUI (Voice User Interfaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicaciones\n",
    "- Self-driving car: Limites de la ruta, peatones, otros autos, etc\n",
    "- Analisis de imágenes médicas\n",
    "- Etiquetado de foto y reconocimiento facial\n",
    "- Búsqueda de imágenes (Image retrieval)\n",
    "- Colocación de leyendas a las imágenes (Image captioning)\n",
    "- Reconocimiento de emociones (Inteligencia emocional) (Affectiva)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "- **Entrada de datos**: Imágenes o trama de imágenes (Videos)\n",
    "- **Pre-procesamiento**: Reducción de ruido, Corrección de color, Escalamiento\n",
    "- **Selección de areas de interés**: Detección de objetos y segmentación de imagen\n",
    "- **Extracción de características**\n",
    "- **Predicción/Reconocimiento**: Detección de objeto, 'matcheo' de características\n",
    "- **Acción**\n",
    "\n",
    "Ejemplo reconocimiento de emociones:\n",
    "- Entrada de datos: Imágenes o trama de imágenes de cara\n",
    "- Pre-procesamiento: Reducción de ruido, Corrección de color, Escalamiento\n",
    "- Selección de areas de interés: Detección de cara y cropeado de imagen\n",
    "- Extracción de características: Encontrar los marcadores faciales como nariz, boca y ojos\n",
    "- Predicción/Reconocimiento: Reconocimiento de expresión facil y predicción de sentimiento\n",
    "- Acción\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿En que etapa/s del proceso podríamos aplicar machine learning?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos de datasets y modelos de CNNs\n",
    "Data Set\n",
    "- Imagenet (http://www.image-net.org/): Banco de imagenes. Mirar desafios (http://image-net.org/challenges/LSVRC/2017/)\n",
    "- http://deeplearning.net/datasets/\n",
    "\n",
    "Modelos:\n",
    "- QuocNet \n",
    "- AlexNet \n",
    "- Inception (GoogLeNet) \n",
    "- BN-Inception-v2\n",
    "- Inception-v3\n",
    "\n",
    "(TensorFlow: https://www.tensorflow.org/tutorials/image_recognition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Servicios API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://cloud.google.com/vision/ (Hacer una prueba de la api con imagen)\n",
    "- https://www.ibm.com/watson/services/visual-recognition/\n",
    "- https://azure.microsoft.com/en-us/services/cognitive-services/computer-vision/\n",
    "- https://www.affectiva.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP (Natural Language Processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicaciones\n",
    "- Traducción (Machine translation)\n",
    "- Detección de Spam\n",
    "- Análisis de sentimiento\n",
    "- Sitemas de preguntas/respuestas (VUI?)\n",
    "- Análisis de tópicos\n",
    "- Generación de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "- **Procesamiento de Texto**: Remover Tags de HTML por ejemplo. Puede venir de OCR o reconocimiento de voz. El fin es obtener texto plano. Analizar lowecase, puntuacion, stopwords\n",
    "- **Extracción de características**: Pasar caracteres y palabras a algun tipo de significado para el modelo que querramos aplicar. (Word2Vec, TF-IDF, etc)\n",
    "- **Modelado (Modeling)**: Modelos estadisticos o de ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿En que etapa/s del proceso podríamos aplicar machine learning?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos de modelos\n",
    "Words Embeddings\n",
    "- word2Vec (https://www.tensorflow.org/tutorials/word2vec)\n",
    "- GLoVe https://nlp.stanford.edu/projects/glove/\n",
    "![](./images/words-embeddings.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Servicios API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://cloud.google.com/natural-language/\n",
    "- https://www.ibm.com/watson/products-services/\n",
    "- https://azure.microsoft.com/en-us/services/cognitive-services/text-analytics/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VUI (Voice User Interfaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicaciones\n",
    "- Alexa (Amazon)\n",
    "- Siri (Apple)\n",
    "- OK Google\n",
    "- Cortana (Microsoft)\n",
    "- Traducción en linea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "Voice2Text:\n",
    "\n",
    "- Entrada de datos\n",
    "- Conversión A/D y codificación\n",
    "- Pre-procesamiento: Filtrado pasabanda y reducción de ruido\n",
    "- Extracción de características: Espectrograma\n",
    "- Modelo acústico: Converson de 'features' a fonemas (HMM)\n",
    "- Modelo de lenguaje: ¿Que combinaciones de palabras son mas probables?\n",
    "\n",
    "El pipeline cambia en el caso **text2Voice**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos de modelos y dataset\n",
    "dataset: http://www.openslr.org/12/\n",
    "\n",
    "\n",
    "- HMM (Hidden Markov Models): Considerados como la solución tradicional\n",
    "- DNN (Deep Neural Networds): Estado del arte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Servicios API\n",
    "- https://cloud.google.com/speech/?hl=es\n",
    "- https://www.ibm.com/watson/services/speech-to-text/\n",
    "- https://azure.microsoft.com/en-us/services/cognitive-services/speech/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aind]",
   "language": "python",
   "name": "conda-env-aind-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "318px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "633px",
    "left": "0px",
    "right": "1068px",
    "top": "66px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
